{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "774f53ea",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "In this notebook we will prepare our data for our search function to use. Currently we have data stored in three different csv file.\n",
    "\n",
    ". College_data.csv\n",
    "\n",
    ". ratings.csv\n",
    "\n",
    ". fees.csv\n",
    "\n",
    ". tag.csv\n",
    "\n",
    "\n",
    "It can be computationally expensive to produce analysis results from multiple data-sources for incomming stream of requests. So we will prepare our data and save it in an easily searchable structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c7d07bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the needed modules...\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be454b6",
   "metadata": {},
   "source": [
    "# Define Paths to data file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1cc3fdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_COLLEGE   = f\"{getcwd()}/dataStore/college.csv\"\n",
    "PATH_RATINGS = f\"{getcwd()}/dataStore/ratings.csv\"\n",
    "PATH_FEES   = f\"{getcwd()}/dataStore/fees.csv\"\n",
    "PATH_TAG = f\"{getcwd()}/dataStore/tag.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b43f1b62",
   "metadata": {},
   "source": [
    "# Data Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f2bb90",
   "metadata": {},
   "source": [
    "# Get Data in Dataframes.\n",
    "\n",
    "\n",
    " # Convert data to a single Dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28d73c80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['college_id', 'College_Name', 'State', 'Stream']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from College.csv\n",
    "\"\"\"\n",
    "df_college  = pd.read_csv(PATH_COLLEGE)\n",
    "college_table_columns = df_college.columns.tolist()\n",
    "print(f\"COLUMNS : {college_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ad2a303c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['userId', 'college_id', 'Rating', 'Academic', 'Accommodation', 'Faculty', 'Infrastructure', 'Placement', 'Social_Life', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from ratings.csv\n",
    "\"\"\"\n",
    "df_ratings         = pd.read_csv(PATH_RATINGS)\n",
    "path_table_columns = df_ratings.columns.tolist()\n",
    "print(f\"COLUMNS : {path_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "2f04b118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['college_id', 'UG_fee', 'PG_fee']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from fees.csv\n",
    "\"\"\"\n",
    "df_fees         = pd.read_csv(PATH_FEES)\n",
    "fees_table_columns = df_fees.columns.tolist()\n",
    "print(f\"COLUMNS : {fees_table_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "74230f09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COLUMNS : ['userId', 'college_id', 'tag', 'timestamp']\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    Read data from tag.csv\n",
    "\"\"\"\n",
    "df_tag         = pd.read_csv(PATH_TAG)\n",
    "tag_table_columns = df_tag.columns.tolist()\n",
    "print(f\"COLUMNS : {tag_table_columns}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59790519",
   "metadata": {},
   "source": [
    "# \n",
    "college_id is a common column in all four tables so we will use it as a primary search-key\n",
    "\n",
    "\n",
    "userId is a common key across two tables, so we will use it as a sort key...\n",
    "\n",
    "\n",
    "A user will always search a college by its name so we will create a Global secondary index to be able to perform search our datastore.\n",
    "it will obviously take some extra space but almost negligible as compared to the size of the original data.\n",
    "In addition, It will make our searching faster and efficient so it's a good deal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3bd2c638",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is True  that the column 'id' has unique values for all entries in college dataframe.\n",
      "It is True  that the column 'id' has unique values for all entries in fees dataframe.\n",
      "It is False that the column 'userId'  has unique values for all entries in ratings dataframe.\n",
      "It is False that the column 'userId'  has unique values for all entries in tags dataframe.\n"
     ]
    }
   ],
   "source": [
    "print(f\"It is {pd.Series(df_college['college_id']).is_unique}  that the column 'id' has unique values for all entries in college dataframe.\")\n",
    "print(f\"It is {pd.Series(df_fees['college_id']).is_unique}  that the column 'id' has unique values for all entries in fees dataframe.\")\n",
    "print(f\"It is {pd.Series(df_ratings['userId']).is_unique} that the column 'userId'  has unique values for all entries in ratings dataframe.\")\n",
    "print(f\"It is {pd.Series(df_tag['userId']).is_unique} that the column 'userId'  has unique values for all entries in tags dataframe.\")\n",
    "\n",
    "# Sort college dataframe on the basis of movieId as movieId is unique for all entries...\n",
    "df_college_sorted = df_college.sort_values(by=['college_id'])\n",
    "\n",
    "# Sort fees dataframe on the basis of movieId as movieId is unique for all entries...\n",
    "df_fees_sorted  = df_fees.sort_values(by=['college_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "3d85a665",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from college dataframe...\n",
    "collegeIds = df_college_sorted[\"college_id\"].tolist()\n",
    "College_Names = df_college_sorted[\"College_Name\"].tolist()\n",
    "States = df_college_sorted[\"State\"].tolist()\n",
    "Streams = df_college_sorted[\"Stream\"].tolist()\n",
    "# from fees dataframe...\n",
    "UG_fees  = df_fees_sorted[\"UG_fee\"].tolist()\n",
    "PG_fees  = df_fees_sorted[\"PG_fee\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1856050e",
   "metadata": {},
   "outputs": [],
   "source": [
    "collegeDict             = {}\n",
    "global_secondaryIndex = {}\n",
    "for idx, college_id in enumerate(collegeIds):\n",
    "    collegeDict[college_id] = {\n",
    "        \"Streams\" : Stream[idx],\n",
    "        \"States\"  : State[idx],\n",
    "        \"fees\" : {\n",
    "            \"UG_fees\" : UG_fee[idx], \n",
    "            \"PG_fees\" : PG_fee[idx]\n",
    "    }\n",
    "    }\n",
    "    \n",
    "    global_secondaryIndex[College_Names[idx]] = college_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2181e831",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete veriables which are no longer in use while holding large amount of data.\n",
    "del College_Names\n",
    "del States\n",
    "del Streams\n",
    "del UG_fees\n",
    "del PG_fees"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3748cfef",
   "metadata": {},
   "source": [
    "### Add all user ratings for individual college.\n",
    "\n",
    "\n",
    "The goal is to group all ratings of a college together, so that we will be able to retrieve user ratings of a particular college.\n",
    "\n",
    "Now, this one is a bit tricky as there is no column in the ratings dataframe which offers unique values.\n",
    "\n",
    "So will have to perform grouping.\n",
    "\n",
    "We will use college_id column as it is a common column in all of our data sources and it will make it easy to add the same data in our new college dataset.\n",
    "\n",
    "The procedure defined below may be computationally gross but should be good enough for a single time execution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7171b08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns of ratings table into individual lists...\n",
    "userIds       = df_ratings[\"userId\"].tolist()\n",
    "collegeIds      = df_ratings[\"college_id\"].tolist()\n",
    "user_ratings  = df_ratings[\"Rating\"].tolist()\n",
    "timestamps    = df_ratings[\"timestamp\"].tolist()\n",
    "\n",
    "ratings = {}\n",
    "\n",
    "for idx, mid in enumerate(collegeIds):\n",
    "    # Do the college_d previously exist?\n",
    "    try   : _ = ratings[mid]\n",
    "    # If not, Add it in the record...\n",
    "    except: \n",
    "        ratings[mid]   = [\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_ratings[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        ]\n",
    "    \n",
    "    try   : _ = ratings[mid][userIds[idx]]\n",
    "    except: ratings[mid].append(\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_ratings[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Finally, add the data in the collegeDict...\n",
    "for mid, _ in collegeDict.items():\n",
    "    try   : collegeDict[mid][\"user_rating\"] = ratings[mid][1:]\n",
    "    except: \n",
    "        try   : collegeDict[mid][\"user_rating\"] = [] # If college_id exists in the college dict...\n",
    "        except: pass # If the college_id doesn't exist in our record..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ae3345",
   "metadata": {},
   "source": [
    "###  Add all user given tags for individual college.\n",
    "\n",
    "The goal is to group all tags given to a college togather, so that we will be able to retrieve tags of a particular college.\n",
    "\n",
    "This one is also tricky as there is no column in the tags dataframe which offers unique values.\n",
    "\n",
    "So will have to perform grouping.\n",
    "\n",
    "We will use college_id column as it is a common column in all of our data sources and it will make it easy to add the same data in our new college dataset.\n",
    "\n",
    "The procedure defined below may also be computationally gross but should be good enough for a single time execution..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "fcaa0ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert all columns of ratings table into individual lists...\n",
    "userIds    = df_tag[\"userId\"].tolist()\n",
    "collegeIds   = df_tag[\"college_id\"].tolist()\n",
    "user_tags   = df_tag[\"tag\"].tolist()\n",
    "timestamps = df_tag[\"timestamp\"].tolist()\n",
    "\n",
    "tag = {}\n",
    "for idx, mid in enumerate(collegeIds):\n",
    "    # Do the college_id previously exist?\n",
    "    try   : _ = tag[mid]\n",
    "    # If not, Add it in the record...\n",
    "    except: tag[mid] = [\n",
    "        {\n",
    "            \"userId\"     : userIds[idx],\n",
    "            \"rating\"     : user_tags[idx],\n",
    "            \"time_stamp\" : timestamps[idx]\n",
    "        }\n",
    "    ]\n",
    "    \n",
    "    try   : _ = ratings[mid][userIds[idx]]\n",
    "    except: tag[mid].append(\n",
    "            {\n",
    "                \"userId\"     : userIds[idx],\n",
    "                \"rating\"     : user_tags[idx],\n",
    "                \"time_stamp\" : timestamps[idx]\n",
    "            }\n",
    "        )\n",
    "\n",
    "# Finally, add the data in the collegeDict...\n",
    "for mid, _ in collegeDict.items():\n",
    "    try   : collegeDict[mid][\"tag\"] = tag[mid][1:]\n",
    "    except: \n",
    "        try   : collegeDict[mid][\"tag\"] = [] # If college_id exists in the college dict...\n",
    "        except: del global_secondaryIndex[mid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "31f3c515",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Writing college Data into the disk...\n",
      "[INFO] Writing Global Secondary Index Data into the disk...\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "print(\"[INFO] Writing college Data into the disk...\")\n",
    "with open('dataStore/dataFinal.json', 'w') as fp:\n",
    "    json.dump(collegeDict, fp, sort_keys=True, indent=4)\n",
    "print(\"[INFO] Writing Global Secondary Index Data into the disk...\")\n",
    "with open('dataStore/dataFinal_GIS.json', 'w') as fp:\n",
    "    json.dump(global_secondaryIndex, fp, sort_keys=True, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb52a104",
   "metadata": {},
   "source": [
    "##### At this point, our database is ready and it can handel high inflow of requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "314e9089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
